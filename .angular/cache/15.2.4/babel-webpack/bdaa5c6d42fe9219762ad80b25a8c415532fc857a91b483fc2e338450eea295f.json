{"ast":null,"code":"import * as i0 from \"@angular/core\";\nimport * as i1 from \"@angular/router\";\nimport * as i2 from \"../header/header.component\";\nimport * as i3 from \"../table-of-contents/table-of-contents.component\";\nimport * as i4 from \"../code-box/code-box.component\";\nexport class PysparkComponent {\n  constructor() {\n    this.tableOfContents = [['section1', 'Introduction'], ['section2', 'Download Spark'], ['section3', 'Add Spark to the Path'], ['section4', 'Pyspark Instllation'], ['section5', 'PySpark & MySql Connection']];\n    this.sections = [[]];\n  }\n  ngOnInit() {\n    this.loadScript('./assets/prism.js', 'js');\n    window.onload = () => {\n      this.loadScript('./assets/main.js', 'js');\n    };\n  }\n  loadScript(scriptUrl, Tipo) {\n    if (Tipo == 'js') {\n      const script = document.createElement('script');\n      script.type = 'text/javascript';\n      script.src = scriptUrl;\n      document.body.appendChild(script);\n    } else if (Tipo === 'css') {\n      const link = document.createElement('link');\n      link.rel = 'stylesheet';\n      link.type = 'text/css';\n      link.href = scriptUrl;\n      document.head.appendChild(link);\n    }\n  }\n  scrollToSection(elementId) {\n    const elementToScrollTo = document.getElementById(elementId);\n    if (elementToScrollTo) {\n      elementToScrollTo.scrollIntoView({\n        behavior: 'smooth'\n      });\n    }\n  }\n}\nPysparkComponent.ɵfac = function PysparkComponent_Factory(t) {\n  return new (t || PysparkComponent)();\n};\nPysparkComponent.ɵcmp = /*@__PURE__*/i0.ɵɵdefineComponent({\n  type: PysparkComponent,\n  selectors: [[\"app-pyspark\"]],\n  decls: 69,\n  vars: 1,\n  consts: [[\"lang\", \"en\"], [\"charset\", \"UTF-8\"], [\"name\", \"viewport\", \"content\", \"width=device-width, initial-scale=1.0\"], [1, \"global\"], [1, \"toc\"], [3, \"tableOfContents\", \"scrollToElement\"], [1, \"content\"], [\"id\", \"section1\"], [\"href\", \"https://es.wikipedia.org/wiki/Apache_Spark\"], [\"routerLink\", \"/practices/mysql\", \"routerLinkActive\", \"active\"], [1, \"section2\"], [\"code\", \"wget https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\"], [\"code\", \"tar -xvzf spark-3.5.1-bin-hadoop3.tgz\"], [1, \"section3\"], [\"code\", \"nano ~/.bashrc\"], [1, \"section4\"], [\"code\", \"pip install pyspark\"], [\"href\", \"https://spark.apache.org/docs/latest/api/python/getting_started/testing_pyspark.html\"], [\"code\", \"from pyspark.sql import SparkSession\\n                from pyspark.sql.functions import col\\n                \\n                # Create a SparkSession\\n                spark = SparkSession.builder.appName('Testing PySpark Example').getOrCreate()\"], [\"code\", \"sample_data = [{'name': 'John    D.'', 'age': 30},\\n                {'name': 'Alice   G.'', 'age': 25},\\n                {'name': 'Bob  T.'', 'age': 35},\\n                {'name': 'Eve   A.'', 'age': 28}]\\n              \\n              df = spark.createDataFrame(sample_data)\\n              df.show()\"], [\"src\", \"./assets/images/pyspark/df_output.png\", \"alt\", \"\", 2, \"display\", \"block\", \"margin-left\", \"auto\", \"margin-right\", \"auto\", \"max-width\", \"90%\"], [1, \"section5\"]],\n  template: function PysparkComponent_Template(rf, ctx) {\n    if (rf & 1) {\n      i0.ɵɵelementStart(0, \"html\", 0)(1, \"head\");\n      i0.ɵɵelement(2, \"meta\", 1)(3, \"meta\", 2);\n      i0.ɵɵelementStart(4, \"title\");\n      i0.ɵɵtext(5, \"Document\");\n      i0.ɵɵelementEnd()();\n      i0.ɵɵelementStart(6, \"body\");\n      i0.ɵɵelement(7, \"app-header\");\n      i0.ɵɵelementStart(8, \"div\", 3)(9, \"div\", 4)(10, \"app-table-of-contents\", 5);\n      i0.ɵɵlistener(\"scrollToElement\", function PysparkComponent_Template_app_table_of_contents_scrollToElement_10_listener($event) {\n        return ctx.scrollToSection($event);\n      });\n      i0.ɵɵelementEnd()();\n      i0.ɵɵelementStart(11, \"div\", 6)(12, \"div\", 7)(13, \"h2\");\n      i0.ɵɵtext(14, \" Introduction \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(15, \"p\");\n      i0.ɵɵtext(16, \" Apache Spark is an open-source cluster computing framework. It was originally developed at the University of California, at the AMPLab in Berkeley. The code base of the Spark project was later donated to the Apache Software Foundation, which has maintained it since then. \");\n      i0.ɵɵelementStart(17, \"a\", 8);\n      i0.ɵɵtext(18, \"Wikipedia\");\n      i0.ɵɵelementEnd()();\n      i0.ɵɵelementStart(19, \"p\");\n      i0.ɵɵtext(20, \" In this practice i going to show you to install PySpark and to make an integration with MySql using the cloud shell. So, i have a little tutorial for cloud shell, if you need, in the introduction section of this practice: \");\n      i0.ɵɵelementStart(21, \"a\", 9);\n      i0.ɵɵtext(22, \"Setup MySql environment\");\n      i0.ɵɵelementEnd();\n      i0.ɵɵtext(23, \". \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(24, \"p\");\n      i0.ɵɵtext(25, \" Spark needs java to works, but in cloud shell you don't have to worry about that. I just download Spark from its web page, add the environment variable to the path and install PySpark. \");\n      i0.ɵɵelementEnd()();\n      i0.ɵɵelementStart(26, \"div\", 10)(27, \"h2\");\n      i0.ɵɵtext(28, \"Download Spark\");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(29, \"p\");\n      i0.ɵɵtext(30, \" In the path '/home/<username>/' create a folder called Spark, open the terminal in this folder and then run the next commands \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelement(31, \"app-code-box\", 11)(32, \"app-code-box\", 12);\n      i0.ɵɵelementStart(33, \"p\");\n      i0.ɵɵtext(34, \"The spark version i am using is clearly '3.5.1'. The java and python version in cloud shell are '17.0.10 and '3.9.2', respectively.\");\n      i0.ɵɵelementEnd()();\n      i0.ɵɵelementStart(35, \"div\", 13)(36, \"h2\");\n      i0.ɵɵtext(37, \"Add Spark to the Path\");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(38, \"p\");\n      i0.ɵɵtext(39, \" Now, open the '.bashrc' and sroll to the last line. You can use \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelement(40, \"app-code-box\", 14);\n      i0.ɵɵelementStart(41, \"p\");\n      i0.ɵɵtext(42, \" Or just open the file with Code OSS. Now, define the 'SPARK_HOME' variable, just paste \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(43, \"ul\")(44, \"li\");\n      i0.ɵɵtext(45, \" \\\"SPARK_HOME=/home/<username>/Spark/spark-3.5.1-bin-hadoop3\\\" \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(46, \"li\");\n      i0.ɵɵtext(47, \" \\\"export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\\\" \");\n      i0.ɵɵelementEnd()()();\n      i0.ɵɵelementStart(48, \"div\", 15)(49, \"h2\");\n      i0.ɵɵtext(50, \"PySpark Installation\");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(51, \"p\");\n      i0.ɵɵtext(52, \" Create a python environment and then install it th PySpark framework \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelement(53, \"app-code-box\", 16);\n      i0.ɵɵelementStart(54, \"p\");\n      i0.ɵɵtext(55, \" Next, open a Jupyter notebook in Code OSS, just create a '.ipynb' file and let the editor install the requirements that the editor needs. Don't forget select the environment where you install PySpark in Code OSS, you can add your environment using ctrl + shift + p. \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(56, \"p\");\n      i0.ɵɵtext(57, \" After that, you can run the next piece of code in spark, i recommend see the \");\n      i0.ɵɵelementStart(58, \"a\", 17);\n      i0.ɵɵtext(59, \"documentation\");\n      i0.ɵɵelementEnd();\n      i0.ɵɵtext(60, \". \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelement(61, \"app-code-box\", 18)(62, \"app-code-box\", 19);\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(63, \"p\");\n      i0.ɵɵtext(64, \" The output must look like this: \");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelement(65, \"img\", 20);\n      i0.ɵɵelementStart(66, \"div\", 21)(67, \"h2\");\n      i0.ɵɵtext(68, \"PySpark & MySql Connection\");\n      i0.ɵɵelementEnd()()()()()();\n    }\n    if (rf & 2) {\n      i0.ɵɵadvance(10);\n      i0.ɵɵproperty(\"tableOfContents\", ctx.tableOfContents);\n    }\n  },\n  dependencies: [i1.RouterLink, i1.RouterLinkActive, i2.HeaderComponent, i3.TableOfContentsComponent, i4.CodeBoxComponent],\n  styles: [\".global[_ngcontent-%COMP%] {\\n    display: flex;\\n    flex-direction: row;\\n    width: 100%;\\n    height: 90vh;\\n    background-color: black;\\n    position: relative;\\n}\\n\\n.toc[_ngcontent-%COMP%] {\\n    display: flex;\\n    flex: 1.1;\\n}\\n\\n.content[_ngcontent-%COMP%] {\\n    padding: 2.1%;\\n    flex: 3.5;\\n    border-style: groove;\\n    border-color: grey;\\n    border-top-right-radius: 20px;\\n    border-bottom-right-radius: 20px;\\n    background-color: white;\\n    overflow-y: scroll;\\n}\\n\\np[_ngcontent-%COMP%] {\\n    text-indent: 2em;\\n}\\n/*# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8uL3NyYy9hcHAvY29tcG9uZW50cy9weXNwYXJrL3B5c3BhcmsuY29tcG9uZW50LmNzcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQTtJQUNJLGFBQWE7SUFDYixtQkFBbUI7SUFDbkIsV0FBVztJQUNYLFlBQVk7SUFDWix1QkFBdUI7SUFDdkIsa0JBQWtCO0FBQ3RCOztBQUVBO0lBQ0ksYUFBYTtJQUNiLFNBQVM7QUFDYjs7QUFFQTtJQUNJLGFBQWE7SUFDYixTQUFTO0lBQ1Qsb0JBQW9CO0lBQ3BCLGtCQUFrQjtJQUNsQiw2QkFBNkI7SUFDN0IsZ0NBQWdDO0lBQ2hDLHVCQUF1QjtJQUN2QixrQkFBa0I7QUFDdEI7O0FBRUE7SUFDSSxnQkFBZ0I7QUFDcEIiLCJzb3VyY2VzQ29udGVudCI6WyIuZ2xvYmFsIHtcbiAgICBkaXNwbGF5OiBmbGV4O1xuICAgIGZsZXgtZGlyZWN0aW9uOiByb3c7XG4gICAgd2lkdGg6IDEwMCU7XG4gICAgaGVpZ2h0OiA5MHZoO1xuICAgIGJhY2tncm91bmQtY29sb3I6IGJsYWNrO1xuICAgIHBvc2l0aW9uOiByZWxhdGl2ZTtcbn1cblxuLnRvYyB7XG4gICAgZGlzcGxheTogZmxleDtcbiAgICBmbGV4OiAxLjE7XG59XG5cbi5jb250ZW50IHtcbiAgICBwYWRkaW5nOiAyLjElO1xuICAgIGZsZXg6IDMuNTtcbiAgICBib3JkZXItc3R5bGU6IGdyb292ZTtcbiAgICBib3JkZXItY29sb3I6IGdyZXk7XG4gICAgYm9yZGVyLXRvcC1yaWdodC1yYWRpdXM6IDIwcHg7XG4gICAgYm9yZGVyLWJvdHRvbS1yaWdodC1yYWRpdXM6IDIwcHg7XG4gICAgYmFja2dyb3VuZC1jb2xvcjogd2hpdGU7XG4gICAgb3ZlcmZsb3cteTogc2Nyb2xsO1xufVxuXG5wIHtcbiAgICB0ZXh0LWluZGVudDogMmVtO1xufVxuXG4iXSwic291cmNlUm9vdCI6IiJ9 */\"]\n});","map":{"version":3,"mappings":";;;;;AAOA,OAAM,MAAOA,gBAAgB;EAL7BC;IAOE,oBAAe,GAAmB,CAChC,CAAC,UAAU,EAAC,cAAc,CAAC,EAC3B,CAAC,UAAU,EAAC,gBAAgB,CAAC,EAC7B,CAAC,UAAU,EAAC,uBAAuB,CAAC,EACpC,CAAC,UAAU,EAAC,qBAAqB,CAAC,EAClC,CAAC,UAAU,EAAC,4BAA4B,CAAC,CAC1C;IAED,aAAQ,GAAkB,CACxB,EAAE,CACH;;EAEDC,QAAQ;IACN,IAAI,CAACC,UAAU,CAAC,mBAAmB,EAAE,IAAI,CAAC;IAC1CC,MAAM,CAACC,MAAM,GAAG,MAAK;MACnB,IAAI,CAACF,UAAU,CAAC,kBAAkB,EAAE,IAAI,CAAC;IAC3C,CAAC;EACH;EAEAA,UAAU,CAACG,SAAiB,EAACC,IAAY;IACvC,IAAIA,IAAI,IAAE,IAAI,EAAC;MACb,MAAMC,MAAM,GAAGC,QAAQ,CAACC,aAAa,CAAC,QAAQ,CAAC;MAC/CF,MAAM,CAACG,IAAI,GAAG,iBAAiB;MAC/BH,MAAM,CAACI,GAAG,GAAGN,SAAS;MACtBG,QAAQ,CAACI,IAAI,CAACC,WAAW,CAACN,MAAM,CAAC;KAClC,MAAO,IAAID,IAAI,KAAK,KAAK,EAAE;MAC1B,MAAMQ,IAAI,GAAGN,QAAQ,CAACC,aAAa,CAAC,MAAM,CAAC;MAC3CK,IAAI,CAACC,GAAG,GAAC,YAAY;MACrBD,IAAI,CAACJ,IAAI,GAAG,UAAU;MACtBI,IAAI,CAACE,IAAI,GAAGX,SAAS;MACrBG,QAAQ,CAACS,IAAI,CAACJ,WAAW,CAACC,IAAI,CAAC;;EAEnC;EAEAI,eAAe,CAACC,SAAiB;IAC/B,MAAMC,iBAAiB,GAAGZ,QAAQ,CAACa,cAAc,CAACF,SAAS,CAAC;IAC5D,IAAIC,iBAAiB,EAAE;MACrBA,iBAAiB,CAACE,cAAc,CAAC;QAAEC,QAAQ,EAAE;MAAQ,CAAE,CAAC;;EAE5D;;AAzCWxB,gBAAgB;mBAAhBA,gBAAgB;AAAA;AAAhBA,gBAAgB;QAAhBA,gBAAgB;EAAAyB;EAAAC;EAAAC;EAAAC;EAAAC;IAAA;MCN7BC,+BAAgB;MAEZA,0BAAsB;MAEtBA,6BAAO;MAAAA,wBAAQ;MAAAA,iBAAQ;MAE3BA,4BAAM;MACFA,6BAAyB;MAEzBA,8BAAoB;MAGRA;QAAA,OAAmBC,2BAAuB;MAAA,EAAC;MAACD,iBAAwB;MAG5EA,+BAAqB;MAGTA,+BACJ;MAAAA,iBAAK;MACLA,0BAAG;MACCA,kSAAgR;MAAAA,6BAAqD;MAAAA,0BAAS;MAAAA,iBAAI;MAEtVA,0BAAG;MACCA,gPACuC;MAAAA,6BAA2D;MAAAA,wCAAuB;MAAAA,iBAAI;MAAAA,mBACjI;MAAAA,iBAAI;MAEJA,0BAAG;MACCA,2MAEJ;MAAAA,iBAAI;MAERA,gCAAsB;MACdA,+BAAc;MAAAA,iBAAK;MAC3BA,0BAAG;MACCA,gJACJ;MAAAA,iBAAI;MACJA,oCAAgH;MAEhHA,0BAAG;MAAAA,oJAAmI;MAAAA,iBAAI;MAG1IA,gCAAsB;MACdA,sCAAqB;MAAAA,iBAAK;MAC9BA,0BAAG;MACCA,kFACJ;MAAAA,iBAAI;MACJA,oCAAmD;MACnDA,0BAAG;MACCA,yGACJ;MAAAA,iBAAI;MACJA,2BAAI;MAEKA,gFACL;MAAAA,iBAAK;MACLA,2BAAI;MACAA,yEACJ;MAAAA,iBAAK;MAGbA,gCAAsB;MACdA,qCAAoB;MAAAA,iBAAK;MAC7BA,0BAAG;MACCA,uFACJ;MAAAA,iBAAI;MACJA,oCAAwD;MACxDA,0BAAG;MACCA,4RAGJ;MAAAA,iBAAI;MACJA,0BAAG;MACCA,+FAA6E;MAAAA,8BAA+F;MAAAA,8BAAa;MAAAA,iBAAI;MAAAA,mBACjM;MAAAA,iBAAI;MACJA,oCAI8F;MAQlGA,iBAAM;MACNA,0BAAG;MACCA,kDACJ;MAAAA,iBAAI;MACJA,2BACsG;MAEtGA,gCAAsB;MACdA,2CAA0B;MAAAA,iBAAK;;;MApFhBA,gBAAmC;MAAnCA,qDAAmC","names":["PysparkComponent","constructor","ngOnInit","loadScript","window","onload","scriptUrl","Tipo","script","document","createElement","type","src","body","appendChild","link","rel","href","head","scrollToSection","elementId","elementToScrollTo","getElementById","scrollIntoView","behavior","selectors","decls","vars","consts","template","i0","ctx"],"sourceRoot":"","sources":["/home/lmdc/Documents/WebPage/src/app/components/pyspark/pyspark.component.ts","/home/lmdc/Documents/WebPage/src/app/components/pyspark/pyspark.component.html"],"sourcesContent":["import { Component } from '@angular/core';\n\n@Component({\n  selector: 'app-pyspark',\n  templateUrl: './pyspark.component.html',\n  styleUrls: ['./pyspark.component.css']\n})\nexport class PysparkComponent {\n\n  tableOfContents: Array<string>[]= [\n    ['section1','Introduction'],\n    ['section2','Download Spark'],\n    ['section3','Add Spark to the Path'],\n    ['section4','Pyspark Instllation'],\n    ['section5','PySpark & MySql Connection']\n  ];\n\n  sections: Array<string>[]=[\n    []\n  ]\n\n  ngOnInit() {      \n    this.loadScript('./assets/prism.js', 'js');\n    window.onload = () => {\n      this.loadScript('./assets/main.js', 'js');\n    };\n  }\n\n  loadScript(scriptUrl: string,Tipo: string) {\n    if (Tipo=='js'){\n      const script = document.createElement('script');\n      script.type = 'text/javascript';\n      script.src = scriptUrl;\n      document.body.appendChild(script);\n    }  else if (Tipo === 'css') {\n      const link = document.createElement('link');\n      link.rel='stylesheet'\n      link.type = 'text/css';\n      link.href = scriptUrl;\n      document.head.appendChild(link);\n    }   \n  }\n\n  scrollToSection(elementId: string): void {\n    const elementToScrollTo = document.getElementById(elementId);\n    if (elementToScrollTo) {\n      elementToScrollTo.scrollIntoView({ behavior: 'smooth' });\n    }\n  }\n\n}\n","<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n</head>\n<body>\n    <app-header></app-header>\n\n    <div class=\"global\">\n        <div class=\"toc\">\n            <app-table-of-contents [tableOfContents]=\"tableOfContents\"\n                (scrollToElement)=\"scrollToSection($event)\"></app-table-of-contents>\n        </div>\n\n        <div class=\"content\">\n            <div id=\"section1\">\n                <h2>\n                    Introduction\n                </h2>\n                <p>\n                    Apache Spark is an open-source cluster computing framework. It was originally developed at the University of California, at the AMPLab in Berkeley. The code base of the Spark project was later donated to the Apache Software Foundation, which has maintained it since then. <a href=\"https://es.wikipedia.org/wiki/Apache_Spark\">Wikipedia</a>\n                </p>\n                <p>\n                    In this practice i going to show you to install PySpark and to make an integration with MySql using the cloud shell. So, i have a little tutorial for cloud shell, if you need, in the\n                    introduction section of this practice: <a routerLink=\"/practices/mysql\" routerLinkActive=\"active\">Setup MySql environment</a>.\n                </p>\n                \n                <p>\n                    Spark needs java to works, but in cloud shell you don't have to worry about that. I just download Spark from its\n                    web page, add the environment variable to the path and install PySpark.\n                </p>\n            </div>\n            <div class=\"section2\">\n                <h2>Download Spark</h2>                \n            <p>\n                In the path '/home/&lt;username&gt;/' create a folder called Spark, open the terminal in this folder and then run the next commands\n            </p>\n            <app-code-box code=\"wget https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\"></app-code-box>            \n            <app-code-box code=\"tar -xvzf spark-3.5.1-bin-hadoop3.tgz\"></app-code-box>\n            <p>The spark version i am using is clearly '3.5.1'. The java and python version in cloud shell are '17.0.10 and '3.9.2', respectively.</p>\n            </div>\n\n            <div class=\"section3\">\n                <h2>Add Spark to the Path</h2>\n                <p>\n                    Now, open the '.bashrc' and sroll to the last line. You can use\n                </p>\n                <app-code-box code=\"nano ~/.bashrc\"></app-code-box>\n                <p>\n                    Or just open the file with Code OSS. Now, define the 'SPARK_HOME' variable, just paste                    \n                </p>                            \n                <ul>\n                    <li>\n                         \"SPARK_HOME=/home/&lt;username&gt;/Spark/spark-3.5.1-bin-hadoop3\"\n                    </li>\n                    <li>\n                        \"export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\"\n                    </li>\n                </ul>\n            </div>\n            <div class=\"section4\">\n                <h2>PySpark Installation</h2>\n                <p>\n                    Create a python environment and then install it th PySpark framework\n                </p>\n                <app-code-box code=\"pip install pyspark\"></app-code-box>\n                <p>\n                    Next, open a Jupyter notebook in Code OSS, just create a '.ipynb' file and let the editor install the requirements that\n                    the editor needs. Don't forget select the environment where you install PySpark in Code OSS, you can add your environment using\n                    ctrl + shift + p.\n                </p>\n                <p>\n                    After that, you can run the next piece of code in spark, i recommend see the <a href=\"https://spark.apache.org/docs/latest/api/python/getting_started/testing_pyspark.html\">documentation</a>.\n                </p>\n                <app-code-box code=\"from pyspark.sql import SparkSession\n                from pyspark.sql.functions import col\n                \n                # Create a SparkSession\n                spark = SparkSession.builder.appName('Testing PySpark Example').getOrCreate()\"></app-code-box>\n                <app-code-box code=\"sample_data = [{'name': 'John    D.'', 'age': 30},\n                {'name': 'Alice   G.'', 'age': 25},\n                {'name': 'Bob  T.'', 'age': 35},\n                {'name': 'Eve   A.'', 'age': 28}]\n              \n              df = spark.createDataFrame(sample_data)\n              df.show()\"></app-code-box>\n            </div>\n            <p>\n                The output must look like this:\n            </p>\n            <img src=\"./assets/images/pyspark/df_output.png\"\n                            style=\"display: block; margin-left: auto; margin-right: auto; max-width: 90%;\" alt=\"\">\n            \n            <div class=\"section5\">\n                <h2>PySpark & MySql Connection</h2>\n                \n            </div>\n        </div>\n    </div>\n</body>\n</html>\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}